{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a5dcb80",
   "metadata": {},
   "source": [
    "# 非线性规划 Nonlinear Programming\n",
    "\n",
    "xyfJASON\n",
    "\n",
    "## 1 概述\n",
    "\n",
    "若目标函数或约束条件包含非线性函数，则称这种规划问题是非线性规划问题。\n",
    "\n",
    "没有通用的算法，各个方法都有自己特定的使用范围。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4216cae3",
   "metadata": {},
   "source": [
    "## 2 算法与代码\n",
    "\n",
    "使用 `scipy.optimize.minimize`，提供了众多优化方法。\n",
    "\n",
    "Documentation: https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html\n",
    "\n",
    "\n",
    "\n",
    "|     方法     | 约束条件 |                 使用算法                  | 是否需要<br>梯度向量<br>海塞矩阵 |                             备注                             |\n",
    "| :----------: | :------: | :---------------------------------------: | :------------------------------: | :----------------------------------------------------------: |\n",
    "|      CG      |  无约束  |      nonlinear conjugate<br>gradient      |              是；否              |                                                              |\n",
    "|     BFGS     |  无约束  |               quasi-Newton                |              是；否              |   在非光滑优化上都能有很好的表现<br>同时返回近似海塞逆矩阵   |\n",
    "|  Newton-CG   |  无约束  |             truncated Newton              |              是；是              |                        适合大规模问题                        |\n",
    "|    dogleg    |  无约束  |           dog-leg trust-region            |      是；是<br>（要求正定）      |                                                              |\n",
    "|  trust-ncg   |  无约束  | Newton conjugate<br>gradient trust-region |              是；是              |                        适合大规模问题                        |\n",
    "| trust-krylov |  无约束  |        Newton GLTR<br>trust-region        |              是；是              |           适合大规模问题<br>中规模和大规模推荐使用           |\n",
    "| trust-exact  |  无约束  |                trust-exact                |              是；是              |                  小规模和中规模最为推荐使用                  |\n",
    "| Nelder-Mead  | 边界约束 |                  Simplex                  |              否；否              |          适用于许多应用<br>不如要求导函数的方法精确          |\n",
    "|   L-BFGS-B   | 边界约束 |                 L-BFGS-B                  |              是；否              |                    同时返回近似海塞逆矩阵                    |\n",
    "|    Powell    | 边界约束 |            conjugate direction            |              否；否              |                     目标函数无需可导<br>                     |\n",
    "|     TNC      | 边界约束 |             truncated Newton              |              是；否              |        打包了 C 语言实现<br>Newton-CG 的边界约束版本         |\n",
    "|    COBYLA    |  有约束  |                  COBYLA                   |              否；否              |   打包了 FORTRAN 语言实现<br>只支持不等式（大于等于）约束    |\n",
    "|    SLSQP     |  有约束  |  Sequential Least<br>SQuares Programming  |  是；否<br>还需要约束条件的梯度  |                                                              |\n",
    "| trust-constr |  有约束  |               trust-region                |              是；是              | 根据问题自动在两种方法中切换<br>最多功能的约束优化实现<br>用于大规模问题的最适合方法 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118641f0",
   "metadata": {},
   "source": [
    "## 3 例题\n",
    "\n",
    "\n",
    "\n",
    "### 3.1 例一\n",
    "\n",
    "求函数 $f(x)=100(x_2-x_1^2)^2+(1-x_1)^2$ 的极小值。\n",
    "\n",
    "这是无约束问题，梯度和海塞矩阵都比较好算，不妨使用 `trust-exact` 方法：\n",
    "\n",
    "$$\n",
    "\\nabla f(x)=\\begin{bmatrix}-400(x_2-x_1^2)x_1-2(1-x_1)\\\\200(x_2-x_1^2)\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "Hessian(f)=\\begin{bmatrix}\n",
    "-400(x_2-x_1^2)+800x_1^2+2&-400x_1\\\\\n",
    "-400x_1&200\n",
    "\\end{bmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf373818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fun: 1.1524542015768823e-13\n",
      "    hess: array([[ 801.99967846, -399.99991693],\n",
      "       [-399.99991693,  200.        ]])\n",
      "     jac: array([ 1.03264509e-05, -5.37090168e-06])\n",
      " message: 'Optimization terminated successfully.'\n",
      "    nfev: 18\n",
      "    nhev: 18\n",
      "     nit: 17\n",
      "    njev: 15\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([0.99999979, 0.99999956])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "def f(x):\n",
    "    return 100*(x[1]-x[0]*x[0])**2+(1-x[0])**2\n",
    "\n",
    "def grad(x):\n",
    "    g = np.zeros(2)\n",
    "    g[0] = -400*(x[1]-x[0]*x[0])*x[0]-2*(1-x[0])\n",
    "    g[1] = 200*(x[1]-x[0]*x[0])\n",
    "    return g\n",
    "\n",
    "def hessian(x):\n",
    "    h = np.zeros((2, 2))\n",
    "    h[0, 0] = -400*(x[1]-x[0]*x[0])+800*x[0]*x[0]+2\n",
    "    h[0, 1] = -400 * x[0]\n",
    "    h[1, 0] = -400 * x[0]\n",
    "    h[1, 1] = 200\n",
    "    return h\n",
    "\n",
    "res = minimize(fun=f,\n",
    "               x0=np.zeros(2),\n",
    "               method='trust-exact',\n",
    "               jac=grad,\n",
    "               hess=hessian)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cfbe13",
   "metadata": {},
   "source": [
    "### 3.2 例二\n",
    "\n",
    "求 $f(x)=(x-3)^2-1, x\\in[0,5]$ 的最小值。\n",
    "\n",
    "计算梯度：\n",
    "\n",
    "$$\n",
    "\\nabla f(x)=2(x-3)\n",
    "$$\n",
    "\n",
    "这是有边界约束问题，可以使用 L-BFGS-B 方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c754cbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      fun: array([-1.])\n",
      " hess_inv: <1x1 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([0.])\n",
      "  message: 'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "     nfev: 3\n",
      "      nit: 2\n",
      "     njev: 3\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([3.])\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    return (x-3)**2-1\n",
    "\n",
    "def grad(x):\n",
    "    return 2*(x-3)\n",
    "\n",
    "res = minimize(fun=f,\n",
    "               x0=np.array([0]),\n",
    "               method='L-BFGS-B',\n",
    "               jac=grad,\n",
    "               bounds=[(0, 5)])\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f5f0e8",
   "metadata": {},
   "source": [
    "### 3.3 例三\n",
    "\n",
    "已知 $f(x)=e^{x_1}(4x_1^2+2x_2^2+4x_1x_2+2x_2+1)$，求\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "&\\min f(x)\\\\\n",
    "&\\text{s.t.}\\begin{cases}\n",
    "x_1x_2-x_1-x_2\\leqslant -1.5\\\\\n",
    "x_1x_2\\geqslant -10\n",
    "\\end{cases}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "能算梯度，先把梯度算出来：\n",
    "\n",
    "$$\n",
    "\\nabla f(x)=\n",
    "\\begin{bmatrix}\n",
    "e^{x_1}(4x_1^2+2x_2^2+4x_1x_2+8x_1+6x_2+1)\\\\\n",
    "e^{x_1}(4x_1+4x_2+2)\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "这是有约束问题，可以使用 SLSQP 方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6072c6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fun: 0.02355037962417156\n",
      "     jac: array([ 0.01839705, -0.00228436])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 9\n",
      "     nit: 8\n",
      "    njev: 8\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([-9.54740503,  1.04740503])\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    return np.e ** x[0] * (4 * x[0] * x[0] + 2 * x[1] * x[1] + 4 * x[0] * x[1] + 2 * x[1] + 1)\n",
    "\n",
    "def grad(x):\n",
    "    g = np.zeros(2)\n",
    "    g[0] = np.e ** x[0] * (4 * x[0] * x[0] + 2 * x[1] * x[1] + 4 * x[0] * x[1] + 8 * x[0] + 6 * x[1] + 1)\n",
    "    g[1] = np.e ** x[0] * (4 * x[0] + 4 * x[1] + 2)\n",
    "    return g\n",
    "\n",
    "def get_constr():\n",
    "    def constr_f1(x):\n",
    "        return x[0] + x[1] - x[0] * x[1] - 1.5\n",
    "\n",
    "    def constr_grad1(x):\n",
    "        return np.array([1 - x[1], 1 - x[0]])\n",
    "\n",
    "    def constr_f2(x):\n",
    "        return x[0] * x[1] + 10\n",
    "\n",
    "    def constr_grad2(x):\n",
    "        return np.array([x[1], x[0]])\n",
    "\n",
    "    c = [\n",
    "        dict(type='ineq',\n",
    "             fun=constr_f1,\n",
    "             jac=constr_grad1),\n",
    "        dict(type='ineq',\n",
    "             fun=constr_f2,\n",
    "             jac=constr_grad2)\n",
    "        ]\n",
    "    return c\n",
    "\n",
    "constr = get_constr()\n",
    "res = minimize(fun=f,\n",
    "               x0=np.array([-2, 2]),\n",
    "               method='SLSQP',\n",
    "               jac=grad,\n",
    "               constraints=constr)\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
